{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "X = df.drop(['id', 'target'], axis=1)\n",
    "Y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(truth, predictions):\n",
    "    g = np.asarray(np.c_[truth, predictions, np.arange(len(truth))], dtype=np.float)\n",
    "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
    "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
    "    gs -= (len(truth) + 1) / 2.\n",
    "    return gs / len(truth)\n",
    "\n",
    "def gini_xgb(predictions, truth):\n",
    "    truth = truth.get_label()\n",
    "    return 'gini', -1.0 * gini(truth, predictions) / gini(truth, truth)\n",
    "\n",
    "def gini_lgb(truth, predictions):\n",
    "    score = gini(truth, predictions) / gini(truth, truth)\n",
    "    return 'gini' , score, True\n",
    "\n",
    "def gini_sklearn(truth, predictions):\n",
    "    return gini(truth, predictions) / gini(truth, truth)\n",
    "\n",
    "gini_score = make_scorer(gini_sklearn, greater_is_better=True, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fujii\\Anaconda3\\envs\\tesorflow-gpu\\lib\\site-packages\\sklearn\\model_selection\\_split.py:624: FutureWarning: You should specify a value for 'n_splits' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini 0.242 params {'n_estimators': 100, 'max_depth': 10}\n",
      "100%|██████████| 1/1 [01:47<00:00, 107.83s/it, best loss: 0.24160884409532798]\n",
      "Hyperopt estimated optimum {'max_depth': 10.0, 'n_estimators': 100.0}\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    params = {'n_estimators': int(params['n_estimators']), 'max_depth': int(params['max_depth'])}\n",
    "    clf = RandomForestClassifier(n_jobs=4, class_weight='balanced', **params)\n",
    "    score = cross_val_score(clf, X, Y, scoring=gini_scorer, cv=StratifiedKFold()).mean()\n",
    "    print(\"Gini {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'n_estimators' : hp.quniform('n_estimators', 25, 500, 25),\n",
    "    'max_depth' : hp.quniform('max_depth', 1, 10, 1)\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "           space = space,\n",
    "           algo=tpe.suggest,\n",
    "           max_evals=1)\n",
    "\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    params = {\n",
    "        'max_depth' : int(params['max_depth']),\n",
    "        'gamma' : \"{:.3f}\".format(params['gamma']),\n",
    "        'colsample_bytree' : \"{:.3f}\".format(params['colsample_bytree'])\n",
    "    }\n",
    "    \n",
    "    clf = xgb.XGBClassifier(\n",
    "    n_estimators=250,\n",
    "    learning_rate=0.05,\n",
    "    n_jobs=4,\n",
    "    **params)\n",
    "    \n",
    "    score = cross_val_score(clf , X, Y, scoring=gini_score,cv=StratifiedKFold()).mean()\n",
    "    print(\"Gini {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {'max_depth': hp.quniform('max_depth', 2, 8, 1),\n",
    "        'colsample_bytree':hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "        'gamma': hp.uniform('gamma', 0.0,0.5),}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "           space=space,\n",
    "           algo=tpe.suggest,\n",
    "           max_evals=1)\n",
    "\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    params = {\n",
    "        'num_leaves' : int(params['num_leaves']),\n",
    "        'colsample_bytree' : \"{:.3f}\".format(params['colsample_bytree'])\n",
    "    }\n",
    "    \n",
    "    clf = xgb.LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01,\n",
    "    **params)\n",
    "    \n",
    "    score = cross_val_score(clf , X, Y, scoring=gini_score,cv=StratifiedKFold()).mean()\n",
    "    print(\"Gini {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'num_leaves': hp.quniform('num_leaves', 8, 128, 2),\n",
    "        'colsample_bytree':hp.uniform('colsample_bytree', 0.3, 1.0),}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "           space=space,\n",
    "           algo=tpe.suggest,\n",
    "           max_evals=1)\n",
    "\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_jobs=4,\n",
    "    class_weight='balanced',\n",
    "    n_estimators=325,\n",
    "    max_depth=5\n",
    ")\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=250,\n",
    "    learning_rate=0.05,\n",
    "    n_jobs=4,\n",
    "    max_depth=2,\n",
    "    colsample_bytree=0.7,\n",
    "    gamma=0.15\n",
    ")\n",
    "\n",
    "lgbm_model = lgbm.LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01,\n",
    "    num_leaves=16,\n",
    "    colsample_bytree=0.7\n",
    ")\n",
    "\n",
    "models = {\n",
    "    ('Random Forest', rf_model),\n",
    "    ('XGBoost', xgb_model),\n",
    "    ('LightGBM', lgbm_model),\n",
    "}\n",
    "\n",
    "for label, model in models:\n",
    "    scores = cross_val_score(model, X, Y, cv=StratifiedKFold(), scoring=gini_scorer)\n",
    "    print(\"Gini coefficient: %0.4f (+/- %0.4f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
